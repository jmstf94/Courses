{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.86x - Introduction to ML Packages (Part 2)\n",
    "\n",
    "This tutorial is designed to provide a short introduction to deep learning with PyTorch.\n",
    "\n",
    "You can start studying this tutorial as you work through unit 3 of the course.\n",
    "For more resources, check out [the PyTorch tutorials](https://pytorch.org/tutorials/)! There are many more in-depth examples available there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source code for this notebook hosted at: https://github.com/varal7/ml-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "[PyTorch](https://pytorch.org) is a flexible scientific computing package targetted towards gradient-based deep learning. Its low-level API closely follows [NumPy](http://www.numpy.org/). However, there are a several key additions:\n",
    "\n",
    "-  GPU support!\n",
    "-  Automatic differentiation!\n",
    "-  Deep learning modules!\n",
    "-  Data loading!\n",
    "-  And other generally useful goodies.\n",
    "\n",
    "If you don't have GPU enabled hardward, don't worry. Like NumPy, PyTorch runs pre-compiled, highly efficient C code to handle all intensive backend functions.\n",
    "\n",
    "Go to pytorch.org to download the correct package for your computing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing torch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.485220Z",
     "start_time": "2019-02-20T16:35:28.476294Z"
    }
   },
   "source": [
    "### Tensors\n",
    "\n",
    "Tensors are PyTorch's equivalent of NumPy ndarrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.492012Z",
     "start_time": "2019-02-20T16:35:28.487024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[-0.8756, -1.2503],\n",
      "        [ 0.2751, -0.0354]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a bunch of ones\n",
    "some_ones = torch.ones(2, 2)\n",
    "print(some_ones)\n",
    "\n",
    "# Construct a bunch of zeros\n",
    "some_zeros = torch.zeros(2, 2)\n",
    "print(some_zeros)\n",
    "\n",
    "# Construct some normally distributed values\n",
    "some_normals = torch.randn(2, 2)\n",
    "print(some_normals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.497368Z",
     "start_time": "2019-02-20T16:35:28.494171Z"
    },
    "scrolled": true
   },
   "source": [
    "PyTorch tensors and NumPy ndarrays even share the same memory handles, so you can switch between the two types essentially for free:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_tensor = torch.randn(5, 5)\n",
    "numpy_ndarray = torch_tensor.numpy()\n",
    "back_to_torch = torch.from_numpy(numpy_ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.564975Z",
     "start_time": "2019-02-20T16:35:28.499321Z"
    }
   },
   "source": [
    "Like NumPy, there are a zillion different operations you can do with tensors. Best thing to do is to go to https://pytorch.org/docs/stable/tensors.html if you know you want to do something to a tensor but don't know how!\n",
    "\n",
    "We can cover a few major ones here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T16:57:10.540510Z",
     "start_time": "2019-02-19T16:57:10.496709Z"
    }
   },
   "source": [
    "In the Numpy tutorial, we have covered the basics of Numpy, numpy arrays, element-wise operations, matrices operations and generating random matrices. \n",
    "In this section, we'll cover indexing, slicing and broadcasting, which are useful concepts that will be reused in `Pandas` and `PyTorch`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4326, -0.5761,  0.1109,  0.6602, -2.0193],\n",
      "        [-0.9101, -1.9799, -0.3396,  0.3466, -1.0065],\n",
      "        [-0.7128, -2.9539, -1.1928, -0.2384,  0.0864],\n",
      "        [-0.9140,  1.0190,  0.0757, -1.2114,  1.1812],\n",
      "        [ 1.6519,  0.3064,  0.1625,  0.8604,  0.2071]])\n",
      "tensor([[-0.3240,  0.1391, -0.4779,  0.7954, -1.7622],\n",
      "        [-1.9598, -0.2668,  0.0381,  1.1582, -0.1808],\n",
      "        [-2.2505,  0.4396, -0.6331,  0.5664, -0.2762],\n",
      "        [-0.8511, -0.1519,  1.4048,  1.0908, -0.6594],\n",
      "        [ 0.0643,  0.8675, -0.7783, -1.8851, -1.6385]])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors\n",
    "a = torch.randn(5, 5)\n",
    "b = torch.randn(5, 5)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.1928)\n",
      "-1.1928232908248901\n"
     ]
    }
   ],
   "source": [
    "# Indexing by i,j\n",
    "another_tensor = a[2, 2]\n",
    "print(another_tensor)\n",
    "\n",
    "# The above returns a tensor type! To get the python value:\n",
    "python_value = a[2, 2].item()\n",
    "print(python_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1928, -0.2384],\n",
      "        [ 0.0757, -1.2114]])\n"
     ]
    }
   ],
   "source": [
    "# Getting a whole row or column or range\n",
    "first_row = a[0, :]\n",
    "first_column = a[:, 0]\n",
    "combo = a[2:4, 2:4]\n",
    "print(combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition\n",
    "c = a + b\n",
    "\n",
    "# Elementwise multiplication: c_ij = a_ij * b_ij\n",
    "c = a * b\n",
    "\n",
    "# Matrix multiplication: c_ik = a_ij * b_jk\n",
    "c = a.mm(b)\n",
    "\n",
    "# Matrix vector multiplication\n",
    "c = a.matmul(b[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([5])\n",
      "tensor([ 2.6400,  1.4845,  1.2517, -1.1688,  3.6423])\n",
      "tensor([[ 2.6400],\n",
      "        [ 1.4845],\n",
      "        [ 1.2517],\n",
      "        [-1.1688],\n",
      "        [ 3.6423]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(5, 5)\n",
    "print(a.size())\n",
    "\n",
    "vec = a[:, 0]\n",
    "print(vec.size())\n",
    "\n",
    "# Matrix multiple 5x5 * 5x5 --> 5x5\n",
    "aa = a.mm(a)\n",
    "\n",
    "# matrix vector 5x5 * 5 --> 5\n",
    "v1 = a.matmul(vec)\n",
    "print(v1)\n",
    "\n",
    "\n",
    "vec_as_matrix = vec.view(5, 1)\n",
    "v2 = a.mm(vec_as_matrix)\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-place operations exist to, generally denoted by a trailing '_' (e.g. my_tensor.my_inplace_function_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9375, 0.9375, 0.9375, 0.9375, 0.9375],\n",
       "        [0.9375, 0.9375, 0.9375, 0.9375, 0.9375],\n",
       "        [0.9375, 0.9375, 0.9375, 0.9375, 0.9375],\n",
       "        [0.9375, 0.9375, 0.9375, 0.9375, 0.9375],\n",
       "        [0.9375, 0.9375, 0.9375, 0.9375, 0.9375]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add one to all elements\n",
    "a.add_(1)\n",
    "\n",
    "# Divide all elements by 2\n",
    "a.div_(2)\n",
    "\n",
    "# Set all elements to 0\n",
    "#a.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulate dimensions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10, 1])\n",
      "torch.Size([1, 10, 10])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([50, 2])\n",
      "tensor([[ 0.0585],\n",
      "        [-0.5698]])\n",
      "tensor([[ 0.0585,  0.0585,  0.0585],\n",
      "        [-0.5698, -0.5698, -0.5698]])\n"
     ]
    }
   ],
   "source": [
    "# Add a dummy dimension, e.g. (n, m) --> (n, m, 1)\n",
    "a = torch.randn(10, 10)\n",
    "\n",
    "# At the end\n",
    "print(a.unsqueeze(-1).size())\n",
    "\n",
    "# At the beginning\n",
    "print(a.unsqueeze(0).size())\n",
    "\n",
    "# In the middle\n",
    "print(a.unsqueeze(1).size())\n",
    "\n",
    "# What you give you can take away\n",
    "print(a.unsqueeze(0).squeeze(0).size())\n",
    "\n",
    "# View things differently, i.e. flat\n",
    "print(a.view(100, 1).size())\n",
    "\n",
    "# Or not flat\n",
    "print(a.view(50, 2).size())\n",
    "\n",
    "# Copy data across a new dummy dimension!\n",
    "a = torch.randn(2)\n",
    "a = a.unsqueeze(-1)\n",
    "print(a)\n",
    "print(a.expand(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a GPU..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmstf\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU it is!\n"
     ]
    }
   ],
   "source": [
    "# Check if you have it\n",
    "do_i_have_cuda = torch.cuda.is_available()\n",
    "\n",
    "if do_i_have_cuda:\n",
    "    print('Using fancy GPUs')\n",
    "    # One way\n",
    "    a = a.cuda()\n",
    "    a = a.cpu()\n",
    "\n",
    "    # Another way\n",
    "    device = torch.device('cuda')\n",
    "    a = a.to(device)\n",
    "\n",
    "    device = torch.device('cpu')\n",
    "    a = a.to(device)\n",
    "else:\n",
    "    print('CPU it is!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And many more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Note about Batching\n",
    "\n",
    "In most ML applications we do mini-batch stochastic gradient descent instead of pure stochastic gradient descent.\n",
    "\n",
    "Mini-batch SGD is a step between full gradient descent and stochastic gradient descent by computing the average gradient over a small number of examples.\n",
    "\n",
    "In a nutshell, given `n` examples:\n",
    "- **Full GD:** dL/dw = average over all `n` examples. One step per `n` examples.\n",
    "- **SGD:** dL/dw = point estimate over a single example. `n` steps per `n` examples.\n",
    "- **Mini-batch SGD:** dL/dw = average over `m << n` examples. `n / m` steps per `n` examples.\n",
    "\n",
    "Advantages of mini-batch SGD include a more stable gradient estimate and computational efficiency on modern hardware (exploiting parallelism gives sub-linear to constant time complexity, especially on GPU).\n",
    "\n",
    "In PyTorch, batched tensors are represented as just another dimension. Most of the deep learning modules assume batched tensors as input (even if the batch size is just 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Batched matrix multiply\n",
    "a = torch.randn(10, 5, 5)\n",
    "b = torch.randn(10, 5, 5)\n",
    "\n",
    "# The same as for i in 1 ... 10, c_i = a[i].mm(b[i])\n",
    "c = a.bmm(b)\n",
    "\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.575416Z",
     "start_time": "2019-02-20T16:35:28.571576Z"
    }
   },
   "source": [
    "## Autograd: Automatic Differentiation!\n",
    "\n",
    "Along with the flexible deep learning modules (to follow) this is the best part of using a package PyTorch.\n",
    "\n",
    "What is autograd? It *automatically* computes *gradients*. All those complicated functions you might be using for your model need gradients for back-propagation. Autograd does this auto-magically! (Sorry, you still need to do this by hand for homework 4.)\n",
    "\n",
    "Let's warmup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6299], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# A tensor that will remember gradients\n",
    "x = torch.randn(1, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.581665Z",
     "start_time": "2019-02-20T16:35:28.577506Z"
    }
   },
   "source": [
    "At first the 'grad' parameter is None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.585548Z",
     "start_time": "2019-02-20T16:35:28.583493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do an operation. Take y = e^x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.591506Z",
     "start_time": "2019-02-20T16:35:28.587586Z"
    }
   },
   "outputs": [],
   "source": [
    "y = x.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.596276Z",
     "start_time": "2019-02-20T16:35:28.593558Z"
    }
   },
   "source": [
    "To run the gradient computing magic, call '.backward()' on a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.602746Z",
     "start_time": "2019-02-20T16:35:28.598538Z"
    }
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.610474Z",
     "start_time": "2019-02-20T16:35:28.605443Z"
    }
   },
   "source": [
    "For all dependent variables {x_1, ..., x_n} that were used to compute y, dy/x_i is computed and stored in the x_i.grad field.\n",
    "\n",
    "Here dy/dx = e^x = y. Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.617215Z",
     "start_time": "2019-02-20T16:35:28.613422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8469]) tensor([0.8469], grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(x.grad, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important!** Remember to zero gradients before subsequent calls to backwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1979])\n"
     ]
    }
   ],
   "source": [
    "# Compute another thingy with x.\n",
    "z = x * 2\n",
    "z.backward()\n",
    "\n",
    "# Should be 2! But it will be 2 + e^x.\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.6075])\n",
      "tensor([-4.5359])\n",
      "tensor([0.1979])\n"
     ]
    }
   ],
   "source": [
    "x_a = torch.randn(1, requires_grad=True)\n",
    "x_b = torch.randn(1, requires_grad=True)\n",
    "x = x_a * x_b\n",
    "x1 = x ** 2\n",
    "x2 = 1 / x1\n",
    "x3 = x2.exp()\n",
    "x4 = 1 + x3\n",
    "x5 = x4.log()\n",
    "x6 = x5 ** (1/3)\n",
    "x6.backward()\n",
    "print(x_a.grad)\n",
    "print(x_b.grad)\n",
    "\n",
    "\n",
    "x = torch.randn(1, requires_grad=True)\n",
    "y = torch.tanh(x)\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Also important!** Under the hood PyTorch stores all the stuff required to compute gradients (call stack, cached values, etc). If you want to save a variable just to keep it around (say for logging or plotting) remember to call `.item()` to get the python value and free the PyTorch machinery memory.\n",
    "\n",
    "You can stop auto-grad from running in the background by using the `torch.no_grad()` context manager.\n",
    "\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    do_all_my_things()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.624048Z",
     "start_time": "2019-02-20T16:35:28.619908Z"
    }
   },
   "source": [
    "## Manual Neural Net + Autograd SGD Example (read this while studying unit 3)\n",
    "\n",
    "Before we move on to the full PyTorch wrapper library, let's do a simple NN SGD example by hand.\n",
    "\n",
    "We'll train a one hidden layer feed forward NN on a toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our random seeds\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.630303Z",
     "start_time": "2019-02-20T16:35:28.626019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 100\n",
      "Number of features: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get ourselves a simple dataset\n",
    "from sklearn.datasets import make_classification\n",
    "set_seed(7)\n",
    "X, Y = make_classification(n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class=1)\n",
    "print('Number of examples: %d' % X.shape[0])\n",
    "print('Number of features: %d' % X.shape[1])\n",
    "\n",
    "# Take a peak\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c=Y, s=25, edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch\n",
    "X, Y = torch.from_numpy(X), torch.from_numpy(Y)\n",
    "\n",
    "# Gotcha: \"Expected object of scalar type Float but got scalar type Double\"\n",
    "# If you see this it's because numpy defaults to Doubles whereas pytorch has floats.\n",
    "X, Y = X.float(), Y.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train a one layer neural net to classify this dataset. Let's define the parameter sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T17:16:34.417254Z",
     "start_time": "2019-02-19T17:16:34.411064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define dimensions\n",
    "num_feats = 2\n",
    "hidden_size = 100\n",
    "num_outputs = 1\n",
    "\n",
    "# Learning rate\n",
    "eta = 0.1\n",
    "num_steps = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now run a few steps of SGD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.634813Z",
     "start_time": "2019-02-20T16:35:28.632236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input to hidden weights\n",
    "W1 = torch.randn(hidden_size, num_feats, requires_grad=True)\n",
    "b1 = torch.zeros(hidden_size, requires_grad=True)\n",
    "\n",
    "# Hidden to output\n",
    "W2 = torch.randn(num_outputs, hidden_size, requires_grad=True)\n",
    "b2 = torch.zeros(num_outputs, requires_grad=True)\n",
    "\n",
    "# Group parameters\n",
    "parameters = [W1, b1, W2, b2]\n",
    "\n",
    "# Get random order\n",
    "indices = torch.randperm(X.size(0))\n",
    "\n",
    "# Keep running average losses for a learning curve?\n",
    "avg_loss = []\n",
    "\n",
    "# Run!\n",
    "for step in range(num_steps):\n",
    "    # Get example\n",
    "    i = indices[step % indices.size(0)]\n",
    "    x_i, y_i = X[i], Y[i]\n",
    "    \n",
    "    # Run example\n",
    "    hidden = torch.relu(W1.matmul(x_i) + b1)\n",
    "    y_hat = torch.sigmoid(W2.matmul(hidden) + b2)\n",
    "    \n",
    "    # Compute loss binary cross entropy: -(y_i * log(y_hat) + (1 - y_i) * log(1 - y_hat))\n",
    "    # Epsilon for numerical stability\n",
    "    eps = 1e-6\n",
    "    loss = -(y_i * (y_hat + eps).log() + (1 - y_i) * (1 - y_hat + eps).log())\n",
    "\n",
    "    # Add to our running average learning curve. Don't forget .item()!\n",
    "    if step == 0:\n",
    "        avg_loss.append(loss.item())\n",
    "    else:\n",
    "        old_avg = avg_loss[-1]\n",
    "        new_avg = (loss.item() + old_avg * len(avg_loss)) / (len(avg_loss) + 1)\n",
    "        avg_loss.append(new_avg)\n",
    "    \n",
    "    # Zero out all previous gradients\n",
    "    for param in parameters:\n",
    "        # It might start out as None\n",
    "        if param.grad is not None:\n",
    "            # In place\n",
    "            param.grad.zero_()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update parameters\n",
    "    for param in parameters:\n",
    "        # In place!\n",
    "        param.data = param.data - eta * param.grad\n",
    "    \n",
    "\n",
    "plt.plot(range(num_steps), avg_loss)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.639328Z",
     "start_time": "2019-02-20T16:35:28.636394Z"
    }
   },
   "source": [
    "## torch.nn\n",
    "\n",
    "The `nn` package is where all of the cool neural network stuff is. Layers, loss functions, etc.\n",
    "\n",
    "Let's dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.643927Z",
     "start_time": "2019-02-20T16:35:28.640936Z"
    }
   },
   "source": [
    "### Layers\n",
    "\n",
    "Before we manually defined our linear layers. PyTorch has them for you as sub-classes of `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=10, out_features=10, bias=True)\n",
      "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "RNN(10, 10)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Linear layer: in_features, out_features\n",
    "linear = nn.Linear(10, 10)\n",
    "print(linear)\n",
    "\n",
    "# Convolution layer: in_channels, out_channels, kernel_size, stride\n",
    "conv = nn.Conv2d(1, 20, 5, 1)\n",
    "print(conv)\n",
    "\n",
    "# RNN: num_inputs, num_hidden, num_layers\n",
    "rnn = nn.RNN(10, 10, 1)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2087,  0.0624,  0.0927,  0.2812,  0.0016,  0.2136, -0.1054, -0.2304,\n",
      "         -0.0307,  0.1642],\n",
      "        [-0.1235, -0.2677, -0.1926,  0.0560,  0.3015,  0.0175, -0.2549, -0.1416,\n",
      "          0.1605, -0.0995],\n",
      "        [-0.0427,  0.2353,  0.1162,  0.1936,  0.2839, -0.1041,  0.0458, -0.2373,\n",
      "          0.3143, -0.2120],\n",
      "        [ 0.3006,  0.2895,  0.0688, -0.2734, -0.0102, -0.1303,  0.0969,  0.1788,\n",
      "          0.1761,  0.1016],\n",
      "        [-0.2423, -0.2660,  0.0934, -0.0694,  0.1478,  0.3073,  0.0955, -0.1904,\n",
      "         -0.0913,  0.1948],\n",
      "        [ 0.0300,  0.2156, -0.3031, -0.0390, -0.1542,  0.2403,  0.1383, -0.0424,\n",
      "         -0.2934, -0.0373],\n",
      "        [ 0.2564, -0.0085, -0.0131, -0.2924,  0.2504,  0.2616, -0.2541, -0.2243,\n",
      "          0.0153, -0.1809],\n",
      "        [-0.2588,  0.0992, -0.0820,  0.1096,  0.1257,  0.2816,  0.1879, -0.2973,\n",
      "         -0.2548,  0.2535],\n",
      "        [-0.2687,  0.1933, -0.1927,  0.2537,  0.1788, -0.2183, -0.2614, -0.1386,\n",
      "         -0.1446, -0.1795],\n",
      "        [ 0.2228,  0.0777, -0.0397, -0.0215,  0.1316,  0.0324, -0.0392,  0.2808,\n",
      "          0.2182,  0.0222]], requires_grad=True)\n",
      "['weight', 'bias']\n"
     ]
    }
   ],
   "source": [
    "print(linear.weight)\n",
    "print([k for k,v in conv.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T16:35:28.850451Z",
     "start_time": "2019-02-20T16:35:28.645580Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make our own model!\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input channel to 20 feature maps of 5x5 kernel. Stride 1.\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "\n",
    "        # 20 input channels to 50 feature maps of 5x5 kernel. Stride 1.\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "\n",
    "        # Full connected of final 4x4 image to 500 features\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        \n",
    "        # From 500 to 10 classes\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize it\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note on convolution sizes:\n",
    "\n",
    "Running a kernel over the image reduces the image height/length by kernel_size - 1.\n",
    "\n",
    "Running a max pooling over the image reduces the image heigh/length by a factor of the kernel size.\n",
    "\n",
    "So starting from a 28 x 28 image:\n",
    "\n",
    "-  Run 5x5 conv --> 24 x 24\n",
    "-  Apply 2x2 max pool --> 12 x 12\n",
    "-  Run 5x5 conv --> 8 x 8\n",
    "-  Apply 2x2 max pool --> 4 x 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers\n",
    "\n",
    "PyTorch handles all the optimizing too. There are several algorithms you can learn about later. Here's SGD:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize with model parameters\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating is now as easy as:\n",
    "\n",
    "```python\n",
    "loss = loss_fn()\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "\n",
    "### Full train and test loops\n",
    "Let's look at a full train loop now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    # For things like dropout\n",
    "    model.train()\n",
    "    \n",
    "    # Avg loss\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Iterate through dataset\n",
    "    for data, target in tqdm.tqdm(train_loader):\n",
    "        # Zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Negative log likelihood loss function\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print average loss\n",
    "    print(\"Train Epoch: {}\\t Loss: {:.6f}\".format(epoch, total_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing loops are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "Just going to run mnist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [02:54<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\t Loss: 0.314269\n",
      "\n",
      "Test set: Average loss: 0.0970, Accuracy: 9704/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [02:38<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2\t Loss: 0.086220\n",
      "\n",
      "Test set: Average loss: 0.0670, Accuracy: 9783/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [02:39<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3\t Loss: 0.061102\n",
      "\n",
      "Test set: Average loss: 0.0574, Accuracy: 9814/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [02:47<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4\t Loss: 0.048696\n",
      "\n",
      "Test set: Average loss: 0.0433, Accuracy: 9860/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [02:38<00:00, 12.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5\t Loss: 0.040483\n",
      "\n",
      "Test set: Average loss: 0.0375, Accuracy: 9892/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [02:43<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6\t Loss: 0.034185\n",
      "\n",
      "Test set: Average loss: 0.0344, Accuracy: 9898/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [01:59<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7\t Loss: 0.029713\n",
      "\n",
      "Test set: Average loss: 0.0339, Accuracy: 9896/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [02:04<00:00, 15.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8\t Loss: 0.025874\n",
      "\n",
      "Test set: Average loss: 0.0319, Accuracy: 9893/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [02:11<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9\t Loss: 0.022834\n",
      "\n",
      "Test set: Average loss: 0.0302, Accuracy: 9896/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [02:13<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10\t Loss: 0.020438\n",
      "\n",
      "Test set: Average loss: 0.0284, Accuracy: 9909/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# See the torch DataLoader for more details.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "for epoch in range(1, 10 + 1):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
